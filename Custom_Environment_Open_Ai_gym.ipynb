{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2acb4c27-f8f1-4825-88ad-433ab719d162",
   "metadata": {},
   "source": [
    "# Lets do RL in a Custom Environment created using Open Ai Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8851f3e0-f8e4-49ed-869e-cbad53bfdafc",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faad82bf-5b56-498a-a07c-4c0d98a24cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f8d0e-a64e-4adb-b3ef-9a17336f1f51",
   "metadata": {},
   "source": [
    "## types of spaces avalable in gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17389abc-4cba-42a2-b852-4c5f479253b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27183e50-0b67-427b-bfa1-6814ccc6c4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9531608 , 0.90417665, 0.5649612 ],\n",
       "       [0.6138739 , 0.11115106, 0.99832445],\n",
       "       [0.95112574, 0.5133277 , 0.4084161 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,1,shape=(3,3)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83c3716f-af32-427e-8d39-f5022772cb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,  20,  39],\n",
       "       [ 83,  51,  58],\n",
       "       [150,  39,  55]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0,255,shape=(3,3), dtype=int).sample() # to represent a tensor commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcf60c97-b239-489d-93e2-d6a316c468cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, array([6.229503], dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple((Discrete(2), Box(0,100, shape=(1,)))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cf8d522-f0a0-4ae7-8682-b77dc25785d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('height', 0), ('speed', array([90.53036], dtype=float32))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({'height':Discrete(2), \"speed\":Box(0,100, shape=(1,))}).sample() # created a dictionary of multiple spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "039adfa6-e4db-4004-bf8b-54936d4e3576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59b75ab2-cbf3-4abf-84ae-ae4b9648313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([5,2,2]).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7506339-744e-4098-9d39-df67944ed59d",
   "metadata": {},
   "source": [
    "## Building an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c8eeb-b147-4f4a-af5f-80fe52d8c328",
   "metadata": {},
   "source": [
    "### Build  a shower environment with temperature going to fluctuate between 37 and 39 degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f50d63-8f46-44ad-9986-56f149b29fd6",
   "metadata": {},
   "source": [
    "### then we build an agent to give us a best shower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17e473de-64dc-43cc-9e10-c4b5de7a0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take, down, stay, up\n",
    "        self.action_space = Discrete(3) # 3 actions can take\n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100])) #to store the observation state+action+reward\n",
    "        # Set start temp\n",
    "        self.state = 38 + random.randint(-3,3) # temeperature between 37 and 39\n",
    "        # Set shower length\n",
    "        self.shower_length = 60 #episode length\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        # 0 -1 = -1 temperature reduce\n",
    "        # 1 -1 = 0 no change in temperature\n",
    "        # 2 -1 = 1 temperature increase\n",
    "        self.state += action -1 \n",
    "        \n",
    "        # Reduce shower length by 1 second after every action\n",
    "        self.shower_length -= 1 \n",
    "        \n",
    "        # Calculate reward\n",
    "        if self.state >=37 and self.state <=39: \n",
    "            reward =1 # for comfortable temperature\n",
    "        else: \n",
    "            reward = -1 \n",
    "        \n",
    "        # Check if shower is done\n",
    "        if self.shower_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Apply temperature noise\n",
    "        #self.state += random.randint(-1,1)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        #to visualize\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
    "        # Reset shower time\n",
    "        self.shower_length = 60 \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54ef68e7-739a-4cc8-bbdc-48ad68bce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ccdc922-27f7-4760-86fc-d02945045cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.12013], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "984de5c4-219c-498d-9bb6-263330864aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a580f0f3-00c3-4a40-b7df-b28557bd0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93124dbb-43b2-4df0-812a-d7537aef41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5371b-3cbf-47fc-ae7b-4e0cbdef38c8",
   "metadata": {},
   "source": [
    "# Lets test the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f4fd9ba-93a7-47fe-8f84-cc83e5f80e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:46\n",
      "Episode:2 Score:36\n",
      "Episode:3 Score:-54\n",
      "Episode:4 Score:-10\n",
      "Episode:5 Score:-22\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b8d94-9c41-4cbc-bdc0-cb9ff81ca5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c87381-855e-4dff-8fb0-0050c4df4745",
   "metadata": {},
   "source": [
    "# Lets train the model or the agent using our environment and policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34a0997b-e187-40b6-9b47-b16fe030ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path=os.path.join('pytorch_RL','logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eae5fdac-75a5-4e01-af59-32c22d053d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path) #seting up the agent using multilayerpAgency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3bb33-577d-4bdd-8ce1-cf306bfb7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1fd433-487f-4c09-a1a6-b516a19f8a47",
   "metadata": {},
   "source": [
    "# Lets save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04980e8d-3452-4abc-bb24-f9b6d016a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(shower_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec649f3-037d-48de-ba1c-2628ce189241",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
